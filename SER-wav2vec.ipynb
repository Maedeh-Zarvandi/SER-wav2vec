{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shAWqgrlak2s",
        "outputId": "b8d1b031-7f55-435f-dcd0-e97c4bfd9624"
      },
      "source": [
        "!pip install transformers datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uvj5S_UOnP0"
      },
      "source": [
        "# Load the Wav2vec2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FCkqVubbXJM"
      },
      "source": [
        "from transformers import Wav2Vec2Tokenizer, Wav2Vec2Model, Trainer, TrainingArguments\n",
        "import transformers\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfRq8X3nKwpy"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmikTHyrbsw-",
        "outputId": "4299bb23-da30-4031-c7a0-b46c97286d33"
      },
      "source": [
        "# load model and tokenizer\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\", padding=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:358: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgPzMqhlE2Xw",
        "outputId": "12d00577-4413-40bc-92db-72411fe85d05"
      },
      "source": [
        "# model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcJyM32hOrZY"
      },
      "source": [
        "# Load the IEMOCAP Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCWnxlLyOulx",
        "outputId": "bed4ce33-6881-4437-edc1-7895437b19ac"
      },
      "source": [
        "!wget 'https://storage.googleapis.com/kaggle-data-sets/1041372/1839956/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210420%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210420T125957Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=4a9273e132dc5f97e20d53c5dde9cc8df46c6fa15572553286658b532efc64b603dab5617bccf5b2a76774d0345c0869aa89c7a53d368edf7d0321da5938926ddbcc52155a8f57274f4b022ddb0ebafb1e634165101db9f8f088ce3980fdd3ade3b1bc05bba0ed506d884a4ad43a762924e3ea0bfe0b082b7db7df3051c87076a2b94d02aacd7e2c9cf0dffa26d8c8f97302d440665f2517ae21177e343087adccec852b799e214bf6502d6a26f12ee79eee8ed969dc1f7ce0d27ce9a1c6e2414968e4c1d99f3b805095d063cfbb4d0993848f167f90e292f4c33f0c8b52a526b26e02a52a028970c3047a2746491af464d63813d8b8d6ea1757df2ed45b8aaf' -O archive.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-20 21:04:55--  https://storage.googleapis.com/kaggle-data-sets/1041372/1839956/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210420%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210420T125957Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=4a9273e132dc5f97e20d53c5dde9cc8df46c6fa15572553286658b532efc64b603dab5617bccf5b2a76774d0345c0869aa89c7a53d368edf7d0321da5938926ddbcc52155a8f57274f4b022ddb0ebafb1e634165101db9f8f088ce3980fdd3ade3b1bc05bba0ed506d884a4ad43a762924e3ea0bfe0b082b7db7df3051c87076a2b94d02aacd7e2c9cf0dffa26d8c8f97302d440665f2517ae21177e343087adccec852b799e214bf6502d6a26f12ee79eee8ed969dc1f7ce0d27ce9a1c6e2414968e4c1d99f3b805095d063cfbb4d0993848f167f90e292f4c33f0c8b52a526b26e02a52a028970c3047a2746491af464d63813d8b8d6ea1757df2ed45b8aaf\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.176, 172.217.164.176, 172.217.9.208, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3150577891 (2.9G) [application/zip]\n",
            "Saving to: ‘archive.zip’\n",
            "\n",
            "archive.zip         100%[===================>]   2.93G  42.0MB/s    in 48s     \n",
            "\n",
            "2021-04-20 21:05:43 (62.0 MB/s) - ‘archive.zip’ saved [3150577891/3150577891]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfL_JsigO5bo"
      },
      "source": [
        "!unzip archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-HOUWpQzgJlW",
        "outputId": "cc76ffe5-9eed-43ef-9891-5d420fbeb850"
      },
      "source": [
        "df = []\n",
        "for i in range(1, 6):\n",
        "  df.append(pd.read_csv(f'df_IEMOCAP/df_IEMOCAP/df_iemocap_{i}.csv'))\n",
        "df = pd.concat(df)\n",
        "df = df.reset_index(drop=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>wav_file</th>\n",
              "      <th>emotion</th>\n",
              "      <th>val</th>\n",
              "      <th>act</th>\n",
              "      <th>dom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.2455</td>\n",
              "      <td>11.6400</td>\n",
              "      <td>Ses01F_impro04_F000</td>\n",
              "      <td>neu</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.7448</td>\n",
              "      <td>16.1500</td>\n",
              "      <td>Ses01F_impro04_F001</td>\n",
              "      <td>neu</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>3.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.6000</td>\n",
              "      <td>30.8976</td>\n",
              "      <td>Ses01F_impro04_F002</td>\n",
              "      <td>fru</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>3.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.0090</td>\n",
              "      <td>37.8000</td>\n",
              "      <td>Ses01F_impro04_F003</td>\n",
              "      <td>xxx</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>2.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40.2300</td>\n",
              "      <td>41.9500</td>\n",
              "      <td>Ses01F_impro04_F004</td>\n",
              "      <td>xxx</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>2.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10034</th>\n",
              "      <td>188.6500</td>\n",
              "      <td>199.4600</td>\n",
              "      <td>Ses05M_impro02_M028</td>\n",
              "      <td>sad</td>\n",
              "      <td>2.3333</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>2.6667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10035</th>\n",
              "      <td>200.1000</td>\n",
              "      <td>202.3900</td>\n",
              "      <td>Ses05M_impro02_M029</td>\n",
              "      <td>sad</td>\n",
              "      <td>3.6667</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>2.3333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10036</th>\n",
              "      <td>202.4500</td>\n",
              "      <td>207.4200</td>\n",
              "      <td>Ses05M_impro02_M030</td>\n",
              "      <td>exc</td>\n",
              "      <td>2.6667</td>\n",
              "      <td>3.3333</td>\n",
              "      <td>3.3333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10037</th>\n",
              "      <td>207.4300</td>\n",
              "      <td>212.1200</td>\n",
              "      <td>Ses05M_impro02_M031</td>\n",
              "      <td>xxx</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>3.3333</td>\n",
              "      <td>3.3333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10038</th>\n",
              "      <td>213.4500</td>\n",
              "      <td>217.5800</td>\n",
              "      <td>Ses05M_impro02_M032</td>\n",
              "      <td>xxx</td>\n",
              "      <td>3.3333</td>\n",
              "      <td>2.6667</td>\n",
              "      <td>2.3333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10039 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       start_time  end_time             wav_file  ...     val     act     dom\n",
              "0          7.2455   11.6400  Ses01F_impro04_F000  ...  3.0000  3.0000  3.0000\n",
              "1         11.7448   16.1500  Ses01F_impro04_F001  ...  2.5000  2.5000  3.0000\n",
              "2         18.6000   30.8976  Ses01F_impro04_F002  ...  2.5000  3.5000  3.0000\n",
              "3         35.0090   37.8000  Ses01F_impro04_F003  ...  2.5000  3.0000  2.5000\n",
              "4         40.2300   41.9500  Ses01F_impro04_F004  ...  2.5000  2.5000  2.0000\n",
              "...           ...       ...                  ...  ...     ...     ...     ...\n",
              "10034    188.6500  199.4600  Ses05M_impro02_M028  ...  2.3333  4.0000  2.6667\n",
              "10035    200.1000  202.3900  Ses05M_impro02_M029  ...  3.6667  4.0000  2.3333\n",
              "10036    202.4500  207.4200  Ses05M_impro02_M030  ...  2.6667  3.3333  3.3333\n",
              "10037    207.4300  212.1200  Ses05M_impro02_M031  ...  3.0000  3.3333  3.3333\n",
              "10038    213.4500  217.5800  Ses05M_impro02_M032  ...  3.3333  2.6667  2.3333\n",
              "\n",
              "[10039 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51n9VpctFH-7"
      },
      "source": [
        "wavs = {}\n",
        "train_or_test = {}\n",
        "for wav_file in df.wav_file:\n",
        "  try:\n",
        "    speech, sr = sf.read(f'Train/Train/{wav_file}.wav')\n",
        "    wavs[wav_file] = speech\n",
        "    train_or_test[wav_file] = 'train'\n",
        "  except Exception:\n",
        "    speech, sr = sf.read(f'Test/Test/{wav_file}.wav')\n",
        "    wavs[wav_file] = speech\n",
        "    train_or_test[wav_file] = 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jtuQ0yBoEFm"
      },
      "source": [
        "train_or_test = pd.Series(train_or_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k23eXRbwoUnw"
      },
      "source": [
        "train_or_test.name = 'dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT0ObyiloHpq"
      },
      "source": [
        "df = df.join(train_or_test, on='wav_file')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef-7TRB-pZub"
      },
      "source": [
        "wavs = pd.Series(wavs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5VvGE3HqRKG"
      },
      "source": [
        "wavs.name = 'wav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWNyVdlQqNDe"
      },
      "source": [
        "df = df.join(wavs, on='wav_file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf12LTSXqUAh"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3286XSHFNiJ"
      },
      "source": [
        "classes = {\n",
        "    'xxx': 0,\n",
        "    'fru': 1,\n",
        "    'neu': 2,\n",
        "    'ang': 3,\n",
        "    'sad': 4,\n",
        "    'exc': 5,\n",
        "    'hap': 6,\n",
        "    'sur': 7,\n",
        "    'fea': 8,\n",
        "    'oth': 9,\n",
        "    'dis': 10\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ft-7VvlFgW9"
      },
      "source": [
        "df['emotion'] = df['emotion'].apply(lambda x: classes[x])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxtNmGM8DGYS"
      },
      "source": [
        "class IEMOCAPDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        row = row[['wav', 'emotion']].to_dict()\n",
        "        row['input_values'] = row.pop('wav')\n",
        "        row['labels'] = row.pop('emotion')\n",
        "        return row\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho0pZhosDbjf"
      },
      "source": [
        "train_dataset = IEMOCAPDataset(df[df['dataset'] == 'train'])\n",
        "test_dataset = IEMOCAPDataset(df[df['dataset'] == 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pidBb0lCqlyI"
      },
      "source": [
        "class EmotionRecognizerModel(nn.Module):\n",
        "\n",
        "  def __init__(self, wav2vec, n_classes):\n",
        "    super().__init__()\n",
        "    self.wav2vec = wav2vec\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.linear = nn.Linear(768, n_classes)\n",
        "\n",
        "  def forward(self, input_values, labels, attention_mask=None):\n",
        "    x = self.wav2vec(input_values=input_values, attention_mask=attention_mask)\n",
        "    x = x.last_hidden_state.mean(1)\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMptmHWe-9Nu"
      },
      "source": [
        "emo_rec_model = EmotionRecognizerModel(model, 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6ItkyzqpIRb1",
        "outputId": "da3bd7bc-802c-4e8f-848e-405aa2db8315"
      },
      "source": [
        "emo_rec_model.to(device)\n",
        "emo_rec_model.train()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "optim = transformers.AdamW(emo_rec_model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    for iter, batch in enumerate(train_loader):\n",
        "        optim.zero_grad()\n",
        "        input_values = batch['input_values'].to(device)\n",
        "        # attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = emo_rec_model(input_values.float(), labels=labels)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if iter % 50 == 0:\n",
        "          print(f'Epoch {epoch}/{n_epochs}, iter {iter+1}/{len(train_loader)}, loss={loss.item()}')\n",
        "\n",
        "emo_rec_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/5, iter 1/7869, loss=6.299236297607422\n",
            "Epoch 0/5, iter 51/7869, loss=1.6235957145690918\n",
            "Epoch 0/5, iter 101/7869, loss=1.274369716644287\n",
            "Epoch 0/5, iter 151/7869, loss=1.4767979383468628\n",
            "Epoch 0/5, iter 201/7869, loss=1.9956889152526855\n",
            "Epoch 0/5, iter 251/7869, loss=0.8254945278167725\n",
            "Epoch 0/5, iter 301/7869, loss=1.736586332321167\n",
            "Epoch 0/5, iter 351/7869, loss=1.7417296171188354\n",
            "Epoch 0/5, iter 401/7869, loss=1.4764186143875122\n",
            "Epoch 0/5, iter 451/7869, loss=1.3397687673568726\n",
            "Epoch 0/5, iter 501/7869, loss=1.6839978694915771\n",
            "Epoch 0/5, iter 551/7869, loss=1.9423624277114868\n",
            "Epoch 0/5, iter 601/7869, loss=1.9067742824554443\n",
            "Epoch 0/5, iter 651/7869, loss=2.0585389137268066\n",
            "Epoch 0/5, iter 701/7869, loss=1.9815291166305542\n",
            "Epoch 0/5, iter 751/7869, loss=1.8276491165161133\n",
            "Epoch 0/5, iter 801/7869, loss=2.473792314529419\n",
            "Epoch 0/5, iter 851/7869, loss=1.8772128820419312\n",
            "Epoch 0/5, iter 901/7869, loss=2.143740653991699\n",
            "Epoch 0/5, iter 951/7869, loss=2.2646079063415527\n",
            "Epoch 0/5, iter 1001/7869, loss=2.3517582416534424\n",
            "Epoch 0/5, iter 1051/7869, loss=2.28568172454834\n",
            "Epoch 0/5, iter 1101/7869, loss=2.3562121391296387\n",
            "Epoch 0/5, iter 1151/7869, loss=2.000211477279663\n",
            "Epoch 0/5, iter 1201/7869, loss=1.8719645738601685\n",
            "Epoch 0/5, iter 1251/7869, loss=1.9261986017227173\n",
            "Epoch 0/5, iter 1301/7869, loss=2.87490177154541\n",
            "Epoch 0/5, iter 1351/7869, loss=1.4952985048294067\n",
            "Epoch 0/5, iter 1401/7869, loss=1.2328189611434937\n",
            "Epoch 0/5, iter 1451/7869, loss=1.5665018558502197\n",
            "Epoch 0/5, iter 1501/7869, loss=1.9585134983062744\n",
            "Epoch 0/5, iter 1551/7869, loss=2.4541690349578857\n",
            "Epoch 0/5, iter 1601/7869, loss=2.9135308265686035\n",
            "Epoch 0/5, iter 1651/7869, loss=1.4803752899169922\n",
            "Epoch 0/5, iter 1701/7869, loss=2.047642230987549\n",
            "Epoch 0/5, iter 1751/7869, loss=1.318691611289978\n",
            "Epoch 0/5, iter 1801/7869, loss=2.540762186050415\n",
            "Epoch 0/5, iter 1851/7869, loss=2.347320079803467\n",
            "Epoch 0/5, iter 1901/7869, loss=1.821066975593567\n",
            "Epoch 0/5, iter 1951/7869, loss=2.540839195251465\n",
            "Epoch 0/5, iter 2001/7869, loss=1.3060989379882812\n",
            "Epoch 0/5, iter 2051/7869, loss=1.3799160718917847\n",
            "Epoch 0/5, iter 2101/7869, loss=1.4756709337234497\n",
            "Epoch 0/5, iter 2151/7869, loss=1.3234211206436157\n",
            "Epoch 0/5, iter 2201/7869, loss=2.038693904876709\n",
            "Epoch 0/5, iter 2251/7869, loss=1.8686957359313965\n",
            "Epoch 0/5, iter 2301/7869, loss=2.3911752700805664\n",
            "Epoch 0/5, iter 2351/7869, loss=1.5881086587905884\n",
            "Epoch 0/5, iter 2401/7869, loss=1.8536269664764404\n",
            "Epoch 0/5, iter 2451/7869, loss=2.0387816429138184\n",
            "Epoch 0/5, iter 2501/7869, loss=2.8066816329956055\n",
            "Epoch 0/5, iter 2551/7869, loss=2.089231491088867\n",
            "Epoch 0/5, iter 2601/7869, loss=1.5514758825302124\n",
            "Epoch 0/5, iter 2651/7869, loss=1.4052132368087769\n",
            "Epoch 0/5, iter 2701/7869, loss=1.2926137447357178\n",
            "Epoch 0/5, iter 2751/7869, loss=1.5270599126815796\n",
            "Epoch 0/5, iter 2801/7869, loss=1.5283317565917969\n",
            "Epoch 0/5, iter 2851/7869, loss=1.689212679862976\n",
            "Epoch 0/5, iter 2901/7869, loss=1.5245922803878784\n",
            "Epoch 0/5, iter 2951/7869, loss=2.2418665885925293\n",
            "Epoch 0/5, iter 3001/7869, loss=1.4506539106369019\n",
            "Epoch 0/5, iter 3051/7869, loss=1.8302162885665894\n",
            "Epoch 0/5, iter 3101/7869, loss=2.0206589698791504\n",
            "Epoch 0/5, iter 3151/7869, loss=1.6016292572021484\n",
            "Epoch 0/5, iter 3201/7869, loss=1.5777099132537842\n",
            "Epoch 0/5, iter 3251/7869, loss=2.2412641048431396\n",
            "Epoch 0/5, iter 3301/7869, loss=1.8150737285614014\n",
            "Epoch 0/5, iter 3351/7869, loss=1.803063154220581\n",
            "Epoch 0/5, iter 3401/7869, loss=2.3505849838256836\n",
            "Epoch 0/5, iter 3451/7869, loss=1.804787039756775\n",
            "Epoch 0/5, iter 3501/7869, loss=1.3469555377960205\n",
            "Epoch 0/5, iter 3551/7869, loss=1.8354878425598145\n",
            "Epoch 0/5, iter 3601/7869, loss=1.1444083452224731\n",
            "Epoch 0/5, iter 3651/7869, loss=1.2939786911010742\n",
            "Epoch 0/5, iter 3701/7869, loss=2.489248514175415\n",
            "Epoch 0/5, iter 3751/7869, loss=2.456172466278076\n",
            "Epoch 0/5, iter 3801/7869, loss=2.1168956756591797\n",
            "Epoch 0/5, iter 3851/7869, loss=1.7349414825439453\n",
            "Epoch 0/5, iter 3901/7869, loss=1.6542607545852661\n",
            "Epoch 0/5, iter 3951/7869, loss=1.465591311454773\n",
            "Epoch 0/5, iter 4001/7869, loss=2.1610918045043945\n",
            "Epoch 0/5, iter 4051/7869, loss=1.2235713005065918\n",
            "Epoch 0/5, iter 4101/7869, loss=2.3098416328430176\n",
            "Epoch 0/5, iter 4151/7869, loss=1.926626443862915\n",
            "Epoch 0/5, iter 4201/7869, loss=2.1916565895080566\n",
            "Epoch 0/5, iter 4251/7869, loss=1.2129645347595215\n",
            "Epoch 0/5, iter 4301/7869, loss=2.154139518737793\n",
            "Epoch 0/5, iter 4351/7869, loss=1.7432693243026733\n",
            "Epoch 0/5, iter 4401/7869, loss=1.603926658630371\n",
            "Epoch 0/5, iter 4451/7869, loss=2.3601393699645996\n",
            "Epoch 0/5, iter 4501/7869, loss=2.9525485038757324\n",
            "Epoch 0/5, iter 4551/7869, loss=2.507704019546509\n",
            "Epoch 0/5, iter 4601/7869, loss=2.360008955001831\n",
            "Epoch 0/5, iter 4651/7869, loss=2.1956868171691895\n",
            "Epoch 0/5, iter 4701/7869, loss=2.3008861541748047\n",
            "Epoch 0/5, iter 4751/7869, loss=1.6713711023330688\n",
            "Epoch 0/5, iter 4801/7869, loss=1.681193232536316\n",
            "Epoch 0/5, iter 4851/7869, loss=2.795652389526367\n",
            "Epoch 0/5, iter 4901/7869, loss=2.0068070888519287\n",
            "Epoch 0/5, iter 4951/7869, loss=2.8591692447662354\n",
            "Epoch 0/5, iter 5001/7869, loss=1.5550124645233154\n",
            "Epoch 0/5, iter 5051/7869, loss=1.8675870895385742\n",
            "Epoch 0/5, iter 5101/7869, loss=1.6371533870697021\n",
            "Epoch 0/5, iter 5151/7869, loss=2.1114978790283203\n",
            "Epoch 0/5, iter 5201/7869, loss=1.8408864736557007\n",
            "Epoch 0/5, iter 5251/7869, loss=1.701784372329712\n",
            "Epoch 0/5, iter 5301/7869, loss=1.9627211093902588\n",
            "Epoch 0/5, iter 5351/7869, loss=1.6956465244293213\n",
            "Epoch 0/5, iter 5401/7869, loss=1.8677994012832642\n",
            "Epoch 0/5, iter 5451/7869, loss=1.6509568691253662\n",
            "Epoch 0/5, iter 5501/7869, loss=2.1568703651428223\n",
            "Epoch 0/5, iter 5551/7869, loss=2.2470836639404297\n",
            "Epoch 0/5, iter 5601/7869, loss=1.598660945892334\n",
            "Epoch 0/5, iter 5651/7869, loss=2.320490837097168\n",
            "Epoch 0/5, iter 5701/7869, loss=2.4201114177703857\n",
            "Epoch 0/5, iter 5751/7869, loss=3.192241668701172\n",
            "Epoch 0/5, iter 5801/7869, loss=1.7583611011505127\n",
            "Epoch 0/5, iter 5851/7869, loss=1.3314666748046875\n",
            "Epoch 0/5, iter 5901/7869, loss=1.1598519086837769\n",
            "Epoch 0/5, iter 5951/7869, loss=2.2533082962036133\n",
            "Epoch 0/5, iter 6001/7869, loss=2.2125344276428223\n",
            "Epoch 0/5, iter 6051/7869, loss=1.3827567100524902\n",
            "Epoch 0/5, iter 6101/7869, loss=1.5232402086257935\n",
            "Epoch 0/5, iter 6151/7869, loss=1.3015369176864624\n",
            "Epoch 0/5, iter 6201/7869, loss=2.028620481491089\n",
            "Epoch 0/5, iter 6251/7869, loss=1.8318082094192505\n",
            "Epoch 0/5, iter 6301/7869, loss=1.3392560482025146\n",
            "Epoch 0/5, iter 6351/7869, loss=1.1765964031219482\n",
            "Epoch 0/5, iter 6401/7869, loss=2.3439559936523438\n",
            "Epoch 0/5, iter 6451/7869, loss=1.63789963722229\n",
            "Epoch 0/5, iter 6501/7869, loss=1.7930223941802979\n",
            "Epoch 0/5, iter 6551/7869, loss=1.7516943216323853\n",
            "Epoch 0/5, iter 6601/7869, loss=1.3595784902572632\n",
            "Epoch 0/5, iter 6651/7869, loss=2.654526948928833\n",
            "Epoch 0/5, iter 6701/7869, loss=1.4461766481399536\n",
            "Epoch 0/5, iter 6751/7869, loss=1.6957604885101318\n",
            "Epoch 0/5, iter 6801/7869, loss=1.66746985912323\n",
            "Epoch 0/5, iter 6851/7869, loss=1.5257099866867065\n",
            "Epoch 0/5, iter 6901/7869, loss=1.583686351776123\n",
            "Epoch 0/5, iter 6951/7869, loss=2.229462146759033\n",
            "Epoch 0/5, iter 7001/7869, loss=2.157244920730591\n",
            "Epoch 0/5, iter 7051/7869, loss=1.8892370462417603\n",
            "Epoch 0/5, iter 7101/7869, loss=1.9597673416137695\n",
            "Epoch 0/5, iter 7151/7869, loss=1.3666479587554932\n",
            "Epoch 0/5, iter 7201/7869, loss=2.154634475708008\n",
            "Epoch 0/5, iter 7251/7869, loss=1.354801058769226\n",
            "Epoch 0/5, iter 7301/7869, loss=1.962648868560791\n",
            "Epoch 0/5, iter 7351/7869, loss=2.3262946605682373\n",
            "Epoch 0/5, iter 7401/7869, loss=1.5500333309173584\n",
            "Epoch 0/5, iter 7451/7869, loss=2.1845622062683105\n",
            "Epoch 0/5, iter 7501/7869, loss=1.739029884338379\n",
            "Epoch 0/5, iter 7551/7869, loss=2.0878820419311523\n",
            "Epoch 0/5, iter 7601/7869, loss=2.240363121032715\n",
            "Epoch 0/5, iter 7651/7869, loss=2.1274914741516113\n",
            "Epoch 0/5, iter 7701/7869, loss=1.207316279411316\n",
            "Epoch 0/5, iter 7751/7869, loss=1.3173913955688477\n",
            "Epoch 0/5, iter 7801/7869, loss=1.4671953916549683\n",
            "Epoch 0/5, iter 7851/7869, loss=2.1034374237060547\n",
            "Epoch 1/5, iter 1/7869, loss=1.6686702966690063\n",
            "Epoch 1/5, iter 51/7869, loss=2.7297754287719727\n",
            "Epoch 1/5, iter 101/7869, loss=1.7434881925582886\n",
            "Epoch 1/5, iter 151/7869, loss=1.5657930374145508\n",
            "Epoch 1/5, iter 201/7869, loss=1.505417823791504\n",
            "Epoch 1/5, iter 251/7869, loss=1.459986925125122\n",
            "Epoch 1/5, iter 301/7869, loss=1.4332197904586792\n",
            "Epoch 1/5, iter 351/7869, loss=1.2553809881210327\n",
            "Epoch 1/5, iter 401/7869, loss=2.404770612716675\n",
            "Epoch 1/5, iter 451/7869, loss=1.7734525203704834\n",
            "Epoch 1/5, iter 501/7869, loss=1.2792032957077026\n",
            "Epoch 1/5, iter 551/7869, loss=1.623402714729309\n",
            "Epoch 1/5, iter 601/7869, loss=1.3817676305770874\n",
            "Epoch 1/5, iter 651/7869, loss=2.4177162647247314\n",
            "Epoch 1/5, iter 701/7869, loss=1.4108673334121704\n",
            "Epoch 1/5, iter 751/7869, loss=1.420590877532959\n",
            "Epoch 1/5, iter 801/7869, loss=1.448259949684143\n",
            "Epoch 1/5, iter 851/7869, loss=1.4880754947662354\n",
            "Epoch 1/5, iter 901/7869, loss=1.820651888847351\n",
            "Epoch 1/5, iter 951/7869, loss=2.1656315326690674\n",
            "Epoch 1/5, iter 1001/7869, loss=2.9386138916015625\n",
            "Epoch 1/5, iter 1051/7869, loss=2.246868133544922\n",
            "Epoch 1/5, iter 1101/7869, loss=2.4208967685699463\n",
            "Epoch 1/5, iter 1151/7869, loss=1.7892721891403198\n",
            "Epoch 1/5, iter 1201/7869, loss=2.459494113922119\n",
            "Epoch 1/5, iter 1251/7869, loss=1.592099905014038\n",
            "Epoch 1/5, iter 1301/7869, loss=1.753994107246399\n",
            "Epoch 1/5, iter 1351/7869, loss=1.7713819742202759\n",
            "Epoch 1/5, iter 1401/7869, loss=1.4418216943740845\n",
            "Epoch 1/5, iter 1451/7869, loss=1.3651957511901855\n",
            "Epoch 1/5, iter 1501/7869, loss=2.443378448486328\n",
            "Epoch 1/5, iter 1551/7869, loss=1.3257594108581543\n",
            "Epoch 1/5, iter 1601/7869, loss=2.4635634422302246\n",
            "Epoch 1/5, iter 1651/7869, loss=1.7761503458023071\n",
            "Epoch 1/5, iter 1701/7869, loss=1.4870496988296509\n",
            "Epoch 1/5, iter 1751/7869, loss=1.6714684963226318\n",
            "Epoch 1/5, iter 1801/7869, loss=2.270388126373291\n",
            "Epoch 1/5, iter 1851/7869, loss=1.52902352809906\n",
            "Epoch 1/5, iter 1901/7869, loss=1.7084296941757202\n",
            "Epoch 1/5, iter 1951/7869, loss=1.6034878492355347\n",
            "Epoch 1/5, iter 2001/7869, loss=1.6994801759719849\n",
            "Epoch 1/5, iter 2051/7869, loss=1.752068042755127\n",
            "Epoch 1/5, iter 2101/7869, loss=1.6677976846694946\n",
            "Epoch 1/5, iter 2151/7869, loss=1.7557969093322754\n",
            "Epoch 1/5, iter 2201/7869, loss=1.6267791986465454\n",
            "Epoch 1/5, iter 2251/7869, loss=2.0072970390319824\n",
            "Epoch 1/5, iter 2301/7869, loss=1.574438452720642\n",
            "Epoch 1/5, iter 2351/7869, loss=1.4962074756622314\n",
            "Epoch 1/5, iter 2401/7869, loss=4.913545608520508\n",
            "Epoch 1/5, iter 2451/7869, loss=2.5444650650024414\n",
            "Epoch 1/5, iter 2501/7869, loss=1.338196873664856\n",
            "Epoch 1/5, iter 2551/7869, loss=2.254561424255371\n",
            "Epoch 1/5, iter 2601/7869, loss=1.8389062881469727\n",
            "Epoch 1/5, iter 2651/7869, loss=2.208240032196045\n",
            "Epoch 1/5, iter 2701/7869, loss=1.6234307289123535\n",
            "Epoch 1/5, iter 2751/7869, loss=1.412339210510254\n",
            "Epoch 1/5, iter 2801/7869, loss=2.314553737640381\n",
            "Epoch 1/5, iter 2851/7869, loss=2.2543208599090576\n",
            "Epoch 1/5, iter 2901/7869, loss=1.3782315254211426\n",
            "Epoch 1/5, iter 2951/7869, loss=2.093909502029419\n",
            "Epoch 1/5, iter 3001/7869, loss=1.282888412475586\n",
            "Epoch 1/5, iter 3051/7869, loss=1.9141254425048828\n",
            "Epoch 1/5, iter 3101/7869, loss=2.835160255432129\n",
            "Epoch 1/5, iter 3151/7869, loss=2.0280723571777344\n",
            "Epoch 1/5, iter 3201/7869, loss=1.8401204347610474\n",
            "Epoch 1/5, iter 3251/7869, loss=2.127056121826172\n",
            "Epoch 1/5, iter 3301/7869, loss=4.502057075500488\n",
            "Epoch 1/5, iter 3351/7869, loss=1.6560184955596924\n",
            "Epoch 1/5, iter 3401/7869, loss=1.2971088886260986\n",
            "Epoch 1/5, iter 3451/7869, loss=1.1223973035812378\n",
            "Epoch 1/5, iter 3501/7869, loss=1.9316911697387695\n",
            "Epoch 1/5, iter 3551/7869, loss=2.184885025024414\n",
            "Epoch 1/5, iter 3601/7869, loss=2.530435562133789\n",
            "Epoch 1/5, iter 3651/7869, loss=1.8033570051193237\n",
            "Epoch 1/5, iter 3701/7869, loss=2.826735019683838\n",
            "Epoch 1/5, iter 3751/7869, loss=2.4927518367767334\n",
            "Epoch 1/5, iter 3801/7869, loss=1.4192553758621216\n",
            "Epoch 1/5, iter 3851/7869, loss=2.267352819442749\n",
            "Epoch 1/5, iter 3901/7869, loss=1.465404987335205\n",
            "Epoch 1/5, iter 3951/7869, loss=2.660705089569092\n",
            "Epoch 1/5, iter 4001/7869, loss=2.15495228767395\n",
            "Epoch 1/5, iter 4051/7869, loss=1.9394137859344482\n",
            "Epoch 1/5, iter 4101/7869, loss=1.9341598749160767\n",
            "Epoch 1/5, iter 4151/7869, loss=1.377988576889038\n",
            "Epoch 1/5, iter 4201/7869, loss=2.7096824645996094\n",
            "Epoch 1/5, iter 4251/7869, loss=2.067883014678955\n",
            "Epoch 1/5, iter 4301/7869, loss=2.601881980895996\n",
            "Epoch 1/5, iter 4351/7869, loss=1.7919658422470093\n",
            "Epoch 1/5, iter 4401/7869, loss=2.1491665840148926\n",
            "Epoch 1/5, iter 4451/7869, loss=1.3737438917160034\n",
            "Epoch 1/5, iter 4501/7869, loss=1.3216397762298584\n",
            "Epoch 1/5, iter 4551/7869, loss=1.3622945547103882\n",
            "Epoch 1/5, iter 4601/7869, loss=2.365091562271118\n",
            "Epoch 1/5, iter 4651/7869, loss=2.0296268463134766\n",
            "Epoch 1/5, iter 4701/7869, loss=2.2435660362243652\n",
            "Epoch 1/5, iter 4751/7869, loss=2.3711190223693848\n",
            "Epoch 1/5, iter 4801/7869, loss=2.300856590270996\n",
            "Epoch 1/5, iter 4851/7869, loss=1.6824241876602173\n",
            "Epoch 1/5, iter 4901/7869, loss=2.6827523708343506\n",
            "Epoch 1/5, iter 4951/7869, loss=1.6193987131118774\n",
            "Epoch 1/5, iter 5001/7869, loss=2.1481313705444336\n",
            "Epoch 1/5, iter 5051/7869, loss=2.307791233062744\n",
            "Epoch 1/5, iter 5101/7869, loss=1.59159517288208\n",
            "Epoch 1/5, iter 5151/7869, loss=2.241696834564209\n",
            "Epoch 1/5, iter 5201/7869, loss=1.446610450744629\n",
            "Epoch 1/5, iter 5251/7869, loss=1.721597671508789\n",
            "Epoch 1/5, iter 5301/7869, loss=1.3905766010284424\n",
            "Epoch 1/5, iter 5351/7869, loss=2.7598981857299805\n",
            "Epoch 1/5, iter 5401/7869, loss=1.382401466369629\n",
            "Epoch 1/5, iter 5451/7869, loss=1.7601006031036377\n",
            "Epoch 1/5, iter 5501/7869, loss=1.932721495628357\n",
            "Epoch 1/5, iter 5551/7869, loss=2.594144582748413\n",
            "Epoch 1/5, iter 5601/7869, loss=1.8463377952575684\n",
            "Epoch 1/5, iter 5651/7869, loss=1.4639692306518555\n",
            "Epoch 1/5, iter 5701/7869, loss=1.505488634109497\n",
            "Epoch 1/5, iter 5751/7869, loss=1.7563508749008179\n",
            "Epoch 1/5, iter 5801/7869, loss=1.7200908660888672\n",
            "Epoch 1/5, iter 5851/7869, loss=1.7326364517211914\n",
            "Epoch 1/5, iter 5901/7869, loss=1.681686282157898\n",
            "Epoch 1/5, iter 5951/7869, loss=1.2917871475219727\n",
            "Epoch 1/5, iter 6001/7869, loss=1.318421483039856\n",
            "Epoch 1/5, iter 6051/7869, loss=1.302524447441101\n",
            "Epoch 1/5, iter 6101/7869, loss=1.680648922920227\n",
            "Epoch 1/5, iter 6151/7869, loss=2.2623252868652344\n",
            "Epoch 1/5, iter 6201/7869, loss=1.8727561235427856\n",
            "Epoch 1/5, iter 6251/7869, loss=2.0501315593719482\n",
            "Epoch 1/5, iter 6301/7869, loss=1.7800490856170654\n",
            "Epoch 1/5, iter 6351/7869, loss=1.3374369144439697\n",
            "Epoch 1/5, iter 6401/7869, loss=2.0986156463623047\n",
            "Epoch 1/5, iter 6451/7869, loss=1.7199311256408691\n",
            "Epoch 1/5, iter 6501/7869, loss=1.3582273721694946\n",
            "Epoch 1/5, iter 6551/7869, loss=1.6759101152420044\n",
            "Epoch 1/5, iter 6601/7869, loss=3.0313479900360107\n",
            "Epoch 1/5, iter 6651/7869, loss=1.6316293478012085\n",
            "Epoch 1/5, iter 6701/7869, loss=2.26847767829895\n",
            "Epoch 1/5, iter 6751/7869, loss=2.594202995300293\n",
            "Epoch 1/5, iter 6801/7869, loss=1.5405068397521973\n",
            "Epoch 1/5, iter 6851/7869, loss=1.6144442558288574\n",
            "Epoch 1/5, iter 6901/7869, loss=2.9289233684539795\n",
            "Epoch 1/5, iter 6951/7869, loss=2.4133427143096924\n",
            "Epoch 1/5, iter 7001/7869, loss=1.6967577934265137\n",
            "Epoch 1/5, iter 7051/7869, loss=1.5058612823486328\n",
            "Epoch 1/5, iter 7101/7869, loss=1.2738667726516724\n",
            "Epoch 1/5, iter 7151/7869, loss=1.6200498342514038\n",
            "Epoch 1/5, iter 7201/7869, loss=1.694115400314331\n",
            "Epoch 1/5, iter 7251/7869, loss=1.5494736433029175\n",
            "Epoch 1/5, iter 7301/7869, loss=1.3127918243408203\n",
            "Epoch 1/5, iter 7351/7869, loss=3.159027099609375\n",
            "Epoch 1/5, iter 7401/7869, loss=2.121011972427368\n",
            "Epoch 1/5, iter 7451/7869, loss=1.453949213027954\n",
            "Epoch 1/5, iter 7501/7869, loss=2.3388569355010986\n",
            "Epoch 1/5, iter 7551/7869, loss=2.4492604732513428\n",
            "Epoch 1/5, iter 7601/7869, loss=3.1411218643188477\n",
            "Epoch 1/5, iter 7651/7869, loss=2.3779592514038086\n",
            "Epoch 1/5, iter 7701/7869, loss=2.0274744033813477\n",
            "Epoch 1/5, iter 7751/7869, loss=3.0190768241882324\n",
            "Epoch 1/5, iter 7801/7869, loss=2.0551493167877197\n",
            "Epoch 1/5, iter 7851/7869, loss=1.9328773021697998\n",
            "Epoch 2/5, iter 1/7869, loss=1.9794278144836426\n",
            "Epoch 2/5, iter 51/7869, loss=2.040611743927002\n",
            "Epoch 2/5, iter 101/7869, loss=1.448710560798645\n",
            "Epoch 2/5, iter 151/7869, loss=1.9430525302886963\n",
            "Epoch 2/5, iter 201/7869, loss=1.2937991619110107\n",
            "Epoch 2/5, iter 251/7869, loss=1.288001298904419\n",
            "Epoch 2/5, iter 301/7869, loss=2.5886292457580566\n",
            "Epoch 2/5, iter 351/7869, loss=1.9951081275939941\n",
            "Epoch 2/5, iter 401/7869, loss=2.1417019367218018\n",
            "Epoch 2/5, iter 451/7869, loss=1.741067886352539\n",
            "Epoch 2/5, iter 501/7869, loss=1.3010547161102295\n",
            "Epoch 2/5, iter 551/7869, loss=1.5513986349105835\n",
            "Epoch 2/5, iter 601/7869, loss=2.156925678253174\n",
            "Epoch 2/5, iter 651/7869, loss=2.3251357078552246\n",
            "Epoch 2/5, iter 701/7869, loss=2.154277801513672\n",
            "Epoch 2/5, iter 751/7869, loss=1.5773398876190186\n",
            "Epoch 2/5, iter 801/7869, loss=1.5257418155670166\n",
            "Epoch 2/5, iter 851/7869, loss=1.9224079847335815\n",
            "Epoch 2/5, iter 901/7869, loss=1.9510743618011475\n",
            "Epoch 2/5, iter 951/7869, loss=1.7037304639816284\n",
            "Epoch 2/5, iter 1001/7869, loss=1.9264323711395264\n",
            "Epoch 2/5, iter 1051/7869, loss=2.4822607040405273\n",
            "Epoch 2/5, iter 1101/7869, loss=1.6127300262451172\n",
            "Epoch 2/5, iter 1151/7869, loss=2.030177354812622\n",
            "Epoch 2/5, iter 1201/7869, loss=1.6789617538452148\n",
            "Epoch 2/5, iter 1251/7869, loss=1.468898057937622\n",
            "Epoch 2/5, iter 1301/7869, loss=1.5214101076126099\n",
            "Epoch 2/5, iter 1351/7869, loss=2.0755467414855957\n",
            "Epoch 2/5, iter 1401/7869, loss=1.7264858484268188\n",
            "Epoch 2/5, iter 1451/7869, loss=1.592635154724121\n",
            "Epoch 2/5, iter 1501/7869, loss=1.5186431407928467\n",
            "Epoch 2/5, iter 1551/7869, loss=1.8662066459655762\n",
            "Epoch 2/5, iter 1601/7869, loss=2.2769477367401123\n",
            "Epoch 2/5, iter 1651/7869, loss=1.6295161247253418\n",
            "Epoch 2/5, iter 1701/7869, loss=1.4444844722747803\n",
            "Epoch 2/5, iter 1751/7869, loss=1.608107089996338\n",
            "Epoch 2/5, iter 1801/7869, loss=2.194131851196289\n",
            "Epoch 2/5, iter 1851/7869, loss=1.5027008056640625\n",
            "Epoch 2/5, iter 1901/7869, loss=2.00335955619812\n",
            "Epoch 2/5, iter 1951/7869, loss=1.4607453346252441\n",
            "Epoch 2/5, iter 2001/7869, loss=2.0393972396850586\n",
            "Epoch 2/5, iter 2051/7869, loss=1.3236782550811768\n",
            "Epoch 2/5, iter 2101/7869, loss=1.3617603778839111\n",
            "Epoch 2/5, iter 2151/7869, loss=1.900956630706787\n",
            "Epoch 2/5, iter 2201/7869, loss=1.6939029693603516\n",
            "Epoch 2/5, iter 2251/7869, loss=2.2675399780273438\n",
            "Epoch 2/5, iter 2301/7869, loss=1.3249210119247437\n",
            "Epoch 2/5, iter 2351/7869, loss=2.2338225841522217\n",
            "Epoch 2/5, iter 2401/7869, loss=1.9647703170776367\n",
            "Epoch 2/5, iter 2451/7869, loss=2.131645917892456\n",
            "Epoch 2/5, iter 2501/7869, loss=1.3275748491287231\n",
            "Epoch 2/5, iter 2551/7869, loss=2.14933443069458\n",
            "Epoch 2/5, iter 2601/7869, loss=2.2545251846313477\n",
            "Epoch 2/5, iter 2651/7869, loss=2.3526909351348877\n",
            "Epoch 2/5, iter 2701/7869, loss=2.845006227493286\n",
            "Epoch 2/5, iter 2751/7869, loss=2.9243268966674805\n",
            "Epoch 2/5, iter 2801/7869, loss=1.3833590745925903\n",
            "Epoch 2/5, iter 2851/7869, loss=2.263664722442627\n",
            "Epoch 2/5, iter 2901/7869, loss=1.4719734191894531\n",
            "Epoch 2/5, iter 2951/7869, loss=2.241978645324707\n",
            "Epoch 2/5, iter 3001/7869, loss=1.6539357900619507\n",
            "Epoch 2/5, iter 3051/7869, loss=1.8473680019378662\n",
            "Epoch 2/5, iter 3101/7869, loss=1.7427105903625488\n",
            "Epoch 2/5, iter 3151/7869, loss=1.7178722620010376\n",
            "Epoch 2/5, iter 3201/7869, loss=1.8292005062103271\n",
            "Epoch 2/5, iter 3251/7869, loss=2.2448601722717285\n",
            "Epoch 2/5, iter 3301/7869, loss=1.5013480186462402\n",
            "Epoch 2/5, iter 3351/7869, loss=1.3221452236175537\n",
            "Epoch 2/5, iter 3401/7869, loss=1.3046534061431885\n",
            "Epoch 2/5, iter 3451/7869, loss=1.7824459075927734\n",
            "Epoch 2/5, iter 3501/7869, loss=2.89565372467041\n",
            "Epoch 2/5, iter 3551/7869, loss=2.2610318660736084\n",
            "Epoch 2/5, iter 3601/7869, loss=1.3956025838851929\n",
            "Epoch 2/5, iter 3651/7869, loss=1.3262709379196167\n",
            "Epoch 2/5, iter 3701/7869, loss=1.473236322402954\n",
            "Epoch 2/5, iter 3751/7869, loss=2.3674068450927734\n",
            "Epoch 2/5, iter 3801/7869, loss=2.311173915863037\n",
            "Epoch 2/5, iter 3851/7869, loss=1.7686480283737183\n",
            "Epoch 2/5, iter 3901/7869, loss=1.874410629272461\n",
            "Epoch 2/5, iter 3951/7869, loss=1.2651870250701904\n",
            "Epoch 2/5, iter 4001/7869, loss=2.275282859802246\n",
            "Epoch 2/5, iter 4051/7869, loss=1.3298784494400024\n",
            "Epoch 2/5, iter 4101/7869, loss=1.7900967597961426\n",
            "Epoch 2/5, iter 4151/7869, loss=1.8156880140304565\n",
            "Epoch 2/5, iter 4201/7869, loss=2.984076499938965\n",
            "Epoch 2/5, iter 4251/7869, loss=2.034498691558838\n",
            "Epoch 2/5, iter 4301/7869, loss=2.038405418395996\n",
            "Epoch 2/5, iter 4351/7869, loss=1.798701524734497\n",
            "Epoch 2/5, iter 4401/7869, loss=1.3657994270324707\n",
            "Epoch 2/5, iter 4451/7869, loss=2.8199028968811035\n",
            "Epoch 2/5, iter 4501/7869, loss=1.3469675779342651\n",
            "Epoch 2/5, iter 4551/7869, loss=4.200187683105469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-85b38b290582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}/{n_epochs}, iter {iter+1}/{len(train_loader)}, loss={loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct_bias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No bias correction for Bert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWmTsp4MV1f7",
        "outputId": "54424bf9-1ae2-48be-849c-7cf3ccf1c629"
      },
      "source": [
        "emo_rec_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionRecognizerModel(\n",
              "  (wav2vec): Wav2Vec2Model(\n",
              "    (feature_extractor): Wav2Vec2FeatureExtractor(\n",
              "      (conv_layers): ModuleList(\n",
              "        (0): Wav2Vec2GroupNormConvLayer(\n",
              "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "        )\n",
              "        (1): Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "        )\n",
              "        (2): Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "        )\n",
              "        (3): Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "        )\n",
              "        (4): Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "        )\n",
              "        (5): Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "        )\n",
              "        (6): Wav2Vec2NoLayerNormConvLayer(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (feature_projection): Wav2Vec2FeatureProjection(\n",
              "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): Wav2Vec2Encoder(\n",
              "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
              "        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
              "        (padding): Wav2Vec2SamePadLayer()\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layers): ModuleList(\n",
              "        (0): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): Wav2Vec2EncoderLayer(\n",
              "          (attention): Wav2Vec2Attention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (feed_forward): Wav2Vec2FeedForward(\n",
              "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fWkRK2CWDK2"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxd35Qy0V5Xv",
        "outputId": "7c1f1a85-75aa-4035-f7db-d28d486b4ee2"
      },
      "source": [
        "loss_total = 0\n",
        "preds = []\n",
        "for iter, batch in enumerate(test_loader):\n",
        "    input_values = batch['input_values'].to(device)\n",
        "    # attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    outputs = emo_rec_model(input_values.float(), labels=labels)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    preds.append(outputs.detach().cpu())\n",
        "    loss_total += loss.detach().cpu().item()\n",
        "print(loss_total / len(test_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9321030473928846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep4m4Tb_Woa8"
      },
      "source": [
        "preds = torch.stack(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wFiv8TfXboV"
      },
      "source": [
        "preds_classes = preds.squeeze().argmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5r6k3cnXkQ0"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjsOfmd0XiR1"
      },
      "source": [
        "print(classification_report(test_dataset.df.emotion.values, preds_classes.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8-OFIu9CToa"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-base-timit-demo\",\n",
        "  output_dir=\"./outputs\",\n",
        "  # group_by_length=True,\n",
        "  per_device_train_batch_size=4,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=10,\n",
        "  # fp16=True,\n",
        "  save_steps=500,\n",
        "  eval_steps=500,\n",
        "  logging_steps=500,\n",
        "  learning_rate=1e-4,\n",
        "  weight_decay=0.005,\n",
        "  warmup_steps=1000,\n",
        "  save_total_limit=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ-t6-aLtEpp"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=emo_rec_model,\n",
        "    args=training_args,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtNIIurmC4WS"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-hvW854gMYS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}